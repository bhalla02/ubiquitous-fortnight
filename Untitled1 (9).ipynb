{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9974f369-8eec-4fde-94b3-af34227ff2b8",
   "metadata": {},
   "source": [
    "Q1. Probability Calculation using Bayes' Theorem\n",
    "Given:\n",
    "\n",
    "70% of employees use the company's health insurance plan: \n",
    "ð‘ƒ\n",
    "(\n",
    "ð»\n",
    ")\n",
    "=\n",
    "0.70\n",
    "P(H)=0.70\n",
    "40% of the employees who use the plan are smokers: \n",
    "ð‘ƒ\n",
    "(\n",
    "ð‘†\n",
    "âˆ£\n",
    "ð»\n",
    ")\n",
    "=\n",
    "0.40\n",
    "P(Sâˆ£H)=0.40\n",
    "We need to find the probability that an employee is a smoker given that they use the health insurance plan, which is \n",
    "ð‘ƒ\n",
    "(\n",
    "ð‘†\n",
    "âˆ£\n",
    "ð»\n",
    ")\n",
    "P(Sâˆ£H).\n",
    "\n",
    "Since \n",
    "ð‘ƒ\n",
    "(\n",
    "ð‘†\n",
    "âˆ£\n",
    "ð»\n",
    ")\n",
    "P(Sâˆ£H) is already given as 0.40, there is no further calculation needed.\n",
    "\n",
    "ð‘ƒ\n",
    "(\n",
    "ð‘†\n",
    "âˆ£\n",
    "ð»\n",
    ")\n",
    "=\n",
    "0.40\n",
    "P(Sâˆ£H)=0.40\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q2. Difference between Bernoulli Naive Bayes and Multinomial Naive Bayes\n",
    "Bernoulli Naive Bayes: Assumes that all features are binary (0s and 1s). It is particularly suited for binary/boolean features (e.g., word occurrence in text classification).\n",
    "\n",
    "Multinomial Naive Bayes: Used for discrete count features (e.g., word counts in text classification). It assumes that features follow a multinomial distribution and is particularly suited for cases where feature vectors represent counts.\n",
    "\n",
    "\n",
    "\n",
    "Q3. Handling Missing Values in Bernoulli Naive Bayes\n",
    "Bernoulli Naive Bayes does not handle missing values inherently. If there are missing values, they need to be imputed or dealt with before fitting the model. Common strategies for handling missing values include:\n",
    "\n",
    "Imputation with the mean, median, or mode.\n",
    "Removal of records with missing values.\n",
    "Use of algorithms that can handle missing values directly.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q4. Can Gaussian Naive Bayes be used for Multi-class Classification?\n",
    "Yes, Gaussian Naive Bayes can be used for multi-class classification. It extends naturally to multi-class problems by applying the same principles to each class independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf39075-f4d1-4611-b770-285f9433a6c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m                 results[name][metric]\u001b[38;5;241m.\u001b[39mappend(func(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Calculate mean and standard deviation of each metric for each classifier\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m summary \u001b[38;5;241m=\u001b[39m {name: {metric: (np\u001b[38;5;241m.\u001b[39mmean(scores), np\u001b[38;5;241m.\u001b[39mstd(scores)) \u001b[38;5;28;01mfor\u001b[39;00m metric, scores \u001b[38;5;129;01min\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m name, scores \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, metrics \u001b[38;5;129;01min\u001b[39;00m summary\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 results[name][metric]\u001b[38;5;241m.\u001b[39mappend(func(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Calculate mean and standard deviation of each metric for each classifier\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m summary \u001b[38;5;241m=\u001b[39m {name: {metric: (np\u001b[38;5;241m.\u001b[39mmean(scores), np\u001b[38;5;241m.\u001b[39mstd(scores)) \u001b[38;5;28;01mfor\u001b[39;00m metric, scores \u001b[38;5;129;01min\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m name, scores \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, metrics \u001b[38;5;129;01min\u001b[39;00m summary\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 results[name][metric]\u001b[38;5;241m.\u001b[39mappend(func(y_test, y_pred, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Calculate mean and standard deviation of each metric for each classifier\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m summary \u001b[38;5;241m=\u001b[39m {name: {metric: (\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mmean(scores), np\u001b[38;5;241m.\u001b[39mstd(scores)) \u001b[38;5;28;01mfor\u001b[39;00m metric, scores \u001b[38;5;129;01min\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m name, scores \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, metrics \u001b[38;5;129;01min\u001b[39;00m summary\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#Q5\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, StratifiedKFold\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('spambase.data', header=None)\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    'BernoulliNB': BernoulliNB(),\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'GaussianNB': GaussianNB()\n",
    "}\n",
    "\n",
    "# Define performance metrics\n",
    "metrics = {\n",
    "    'Accuracy': accuracy_score,\n",
    "    'Precision': precision_score,\n",
    "    'Recall': recall_score,\n",
    "    'F1 Score': f1_score\n",
    "}\n",
    "\n",
    "# 10-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "results = {name: {metric: [] for metric in metrics} for name in classifiers}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        for metric, func in metrics.items():\n",
    "            if metric == 'Accuracy':\n",
    "                results[name][metric].append(func(y_test, y_pred))\n",
    "            else:\n",
    "                results[name][metric].append(func(y_test, y_pred, average='binary'))\n",
    "\n",
    "# Calculate mean and standard deviation of each metric for each classifier\n",
    "summary = {name: {metric: (np.mean(scores), np.std(scores)) for metric, scores in scores.items()} for name, scores in results.items()}\n",
    "\n",
    "# Print the results\n",
    "for name, metrics in summary.items():\n",
    "    print(f\"Results for {name}:\")\n",
    "    for metric, (mean, std) in metrics.items():\n",
    "        print(f\"{metric}: {mean:.4f} Â± {std:.4f}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fdc0f8-6697-4062-900f-a7484ab7aeca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
